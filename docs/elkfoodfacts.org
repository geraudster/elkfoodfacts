#+TITLE:     Elastic & food fact checking
#+AUTHOR:    Géraud Dugé de Bernonville
#+EMAIL:     geraud.dugedebernonville@zenika.com
#+DATE:      30/03/2020

* Contexte
** Qualité des aliments & sécurité sanitaire

+ Vache folle
+ Grippe aviaire
+ Perturbateurs endocriniens (pesticides, plastiques et 
 autres substances chimiques...)
+ OGM
+ Allergènes (gluten, crustacés, oeufs, arachides, soja, ...)
+ Cancérogènes (E171 - oxyde de titane *?*)

*** Questions :						       :B_alertblock:
    :PROPERTIES:
    :BEAMER_env: alertblock
    :END:
 + Où trouve-t-on ces éléments ?
 + Quelles catégories de produit sont les plus concernées ?
 + Quelles marques ?

** Mais surtout... Y a t'il du E171 dans la bière ?

[[./images/beer.jpg]]

** Open Food Facts

#+ATTR_LATEX: :width 5cm
[[./images/openfoodfacts-logo-fr.png]]

Base de données sur les produits alimentaires faite par tout le monde,
pour tout le monde.

** Open Food Facts - Mobile

*** Android App 						      :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:

#+ATTR_LATEX: :height 0.75\textheight
[[./images/off-android-app.png]]

*** Additifs 							      :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:

#+ATTR_LATEX: :height 0.75\textheight
[[./images/off-android-app-additives.jpg]]

** Ce qu'on aimerait avoir

[[./images/dashboard.png]]

* Les outils
** Elastic Stack

*** Elasticsearch 						      :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:END:

#+ATTR_LATEX: :height 0.2\textheight
[[./images/icon-elasticsearch-bb.png]]

+ Moteur de recherche
+ Analyse et stockage de données

*** Logstash 							      :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:END:

#+ATTR_LATEX: :height 0.2\textheight
[[./images/icon-logstash-bb.png]]

+ Ingestion des données
  
*** Kibana 							      :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:END:      

#+ATTR_LATEX: :height 0.2\textheight
[[./images/icon-kibana-bb.png]]

+ Visualisation

* Entraînement
** Topo Elasticsearch

*** Document JSON

#+BEGIN_SRC js
{
  "name": "Chips au vinaigre",
  "category" : "apero",
  "lipides" : 20,
  "glucides" : 10,
  "proteines" : 5
}
#+END_SRC

*** API REST

#+BEGIN_SRC js
<GET|POST|PUT|DELETE>
http[s]://<hostname>:<port>/[<index>]/[<type>]/[_<keyword>]]

#+END_SRC

+ index
+ type: _doc
+ _keyword : _search, _mapping,...

** Installation

*** Pré-requis 						       :B_alertblock:
:PROPERTIES:
:BEAMER_env: alertblock
:END:

+ Docker et docker-compose

*** Version 7.x

1. =cd elk-compose=
2. Lancer la stack: =docker-compose up=
3. Ouvrir http://localhost:5601
3. Aller dans _Dev Tools_ (http://localhost:5601/app/kibana#/dev_tools/console)

** Jouons avec Elasticsearch

*** Indexer un document 					    :B_block:BMCOL:
:PROPERTIES:
:BEAMER_env: block
:BEAMER_col: 0.5
:END:

#+BEGIN_SRC json
POST /store/_doc
{
  "name": "Chips au vinaigre",
  "category" : "apero",
  "lipides" : 20,
  "glucides" : 10,
  "proteines" : 5
}

POST /store/_doc
{
  "name": "Langues piquantes",
  "category" : "confiserie",
  "lipides" : 0,
  "glucides" : 90,
  "proteines" : 5
}
#+END_SRC

*** Requêter 				      :B_block:BMCOL:
:PROPERTIES:
:BEAMER_env: block
:BEAMER_col: 0.5
:END:

#+BEGIN_SRC json
GET /store/_search

GET /store/_search?q=langues

GET /store/_search
{
  "query": {
    "match": {
      "name": "langues"
    }
  }
}
#+END_SRC

** Topo Logstash

*** Lancement

#+BEGIN_SRC sh
docker-compose run logstash -f /pipeline/demo/ingest.conf
#+END_SRC

*** Fichier conf

#+BEGIN_SRC ruby
input { ... }
filter { ... }
output { ... }
#+END_SRC

** Jouons avec Logstash - Données de test

1. Récupérer le fichier CSV =sample-fr.openfoodfacts.org.products.csv=
2. Vérifier le fichier =file-input.conf= dans le répertoire pipelines/student
  #+INCLUDE: "../pipelines/student/file-input.conf" src ruby
3. Vérifier le fichier =debug-output.conf=
  #+INCLUDE: "../pipelines/student/debug-output.conf" src ruby
4. Lancer logstash
  #+BEGIN_SRC sh
docker-compose run logstash \
       -f '/pipelines/student/{file-input,debug-output}.conf'
  #+END_SRC
5. Patienter...

** Ajout du filtre CSV

1. Vérifier le fichier =filter.conf= dans le répertoire pipelines/student
  #+INCLUDE: "../pipelines/student/filter.conf" src ruby :lines "-10"
2. Supprimer le fichier =since_db=
3. Lancer logstash
  #+BEGIN_SRC sh
docker-compose run logstash -w 1 \
      -f '/pipelines/student/{file-input,debug-output,filter}.conf'
  #+END_SRC

** Ajout de la sortie Elasticsearch
1. Vérifier le fichier =elastic-output.conf=
  #+INCLUDE: "../pipelines/student/elastic-output.conf" src ruby
2. Lancer logstash
  #+BEGIN_SRC sh
docker-compose run logstash -w 1 \
      -f '/pipelines/student/{file-input,filter,elastic-output}.conf'
  #+END_SRC


*** Dans Kibana > Dev Tools 				      :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:

#+BEGIN_SRC js
GET /openfoodfacts/_search
GET /openfoodfacts/_search?q=Snacks
#+END_SRC

** Query time !

Nombre de catégories:
#+BEGIN_SRC js
GET /openfoodfacts/_search
{
  "aggs": {
    "categories_count": {
      "value_count": {
        "field": "main_category"
      }
    }
  }
}
#+END_SRC


** Query time !

Répartition des additifs par catégories:
#+BEGIN_SRC js
GET /openfoodfacts/_search
{
  "aggs": {
    "par_categorie": {
      "terms": {
        "field": "main_category_fr",
        "size": 10
      },
      "aggs": {
        "par_additif": {
          "terms": {
            "field": "additives_fr"
          }
        }
      }
    }
  }
}
#+END_SRC

** Problème de taille

[[./images/index-management-1.png]]


** Configuration du mapping

#+BEGIN_SRC js
DELETE openfoodfacts

PUT /openfoodfacts
{
    "settings" : {
        "number_of_shards": 3,
        "number_of_replicas": 0
    },
    "mappings": {
        "dynamic_templates": [
            {
                "strings": {
                    "match_mapping_type": "string",
                    "mapping": {
                        "type": "keyword"
                    }
                }
            }
        ]
    }
}
#+END_SRC

** Jouons avec Kibana

*** Navigation dans les données
1. Configurer l'index, décocher *Index contains time-based events*
2. Accéder à l'onglet *Discover*
3. Sélectionner les champs =additives_fr=, =main_category_fr=,...

*** Première visualisation - Nuage des principales catégories
1. Accéder à l'onglet *Visualize*
2. Sélectionner *Tag Cloud*
3. Configurer un bucket *Tags*
   + Aggregation = Terms
   + Field = =main_category_fr=
   + Size = 50
   + Custom Label = Catégories principales
4. Sauvegarder le widget

** Kibana - Suite
*** Tableau des marques
1. Sélectionner *Table*
2. Créer un bucket *Split Rows*
   + Aggregation = Terms
   + Field = =brands=
   + Size = 20
   + Custom Label = Marques
3. Sauvegarder

** Kibana - Mmmmm Donut
*** Donut des allergènes
1. Sélectionner *Pie chart*
2. Créer un bucket *Split Slices*
   + Aggregation = Terms
   + Field = =allergens=
   + Size = 10
   + Custom Label = Allergènes
   + Options > Sélectionner *Donut*
3. Sauvegarder

** Kibana - Fin (?)
*** Histogramme des additifs
1. Sélectionner *Vertical Bar Chart*
2. À vous de jouer...

*** Tag cloud des produits
On veut ça:
[[./images/tagcloud.png]]

** Dashboard

1. Ajouter tous les widgets dans un nouveau dashboard
2. Sauvegarder

* Produit final
** Chargeons toute la base !
+ L'objectif est de voir le résultat avec l'ensemble des données
+ Pour éviter les doublons, on supprime l'index =openfoodfacts=
+ Lancer logstash (attention, utiliser _file-input-full_)
  #+BEGIN_SRC sh
docker-compose run --rm logstash -w 1 \
      -f '/pipelines/student/{file-input-full,filter,elastic-output}.conf'
  #+END_SRC

* Conclusion

** Beer

*** Image							      :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.4
    :END:

[[./images/beer-good.jpg]]

*** Texte							      :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.6
    :END:

Mission accomplie !

+ Requêtes avec Elasticsearch
+ Ingestion de données avec Logstash
+ Visualisation avec Kibana

** Pour aller plus loin

+ Fixer problèmes d'import
  + Champs trop longs
  + Encodage
  + Guillemets mal positionnés
+ Découper les champs, par exemple :
  + E330 - Acide citrique,E150c - Caramel ammoniacal,E300 - Acide ascorbique
  + Frais,Produits laitiers,Desserts,Fromages,Fromages blancs,Fromages-blancs-aromatises
+ Configurer l'analyseur pour utiliser la langue française
+ Utiliser les informations de géolocalisation

** Merci

*** Col1							      :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.3
    :END:

*** ? 							 :B_alertblock:BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.3
    :BEAMER_env: alertblock
    :END:

Questions

*** Col3 							      :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.3
    :BEAMER_opt: 30
    :END:

#+DESCRIPTION: 
#+KEYWORDS: 
#+LANGUAGE:  fr
#+OPTIONS:   H:2 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:   
#+LINK_HOME:
#+startup: beamer
#+LATEX_CLASS: beamer
#+LATEX_CLASS_OPTIONS: [aspectratio=1610,t]
#+BEAMER_FRAME_LEVEL: 2
#+latex_header: \mode<beamer>{\usetheme{CambridgeUS}}
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\scriptsize}
#+LATEX_HEADER: \setbeamertemplate{navigation symbols}{}
#+BEAMER_HEADER: \logo{\includegraphics[height=0.7cm]{images/logo-zenika.png}}
#+LATEX_HEADER: \usepackage[default,osfigures,scale=0.95]{opensans}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
